{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1. Generate 5 batches of 20 randomly generated RGB images of shape (256,512,3).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1. Generate 5 batches of 20 randomly generated RGB images of shape (256,512,3).\n",
    "import numpy as np\n",
    "# Creation of a class to generate random RGB images \n",
    "class RGBImageBatchGenerator:\n",
    "    # Initialization of the class with default values\n",
    "    def __init__(self, num_batches=5, batch_size=20, image_shape=(256, 512, 3)):\n",
    "        \"\"\"\n",
    "        Initializes the generator with default or custom values.\n",
    "\n",
    "        Parameters:\n",
    "        - num_batches (int): Number of batches to generate.\n",
    "        - batch_size (int): Number of images per batch.\n",
    "        - image_shape (tuple): Shape of each image (height, width, channels).\n",
    "        \"\"\"\n",
    "        self.num_batches = num_batches\n",
    "        self.batch_size = batch_size\n",
    "        self.image_shape = image_shape\n",
    "    # Generation of random RGB images\n",
    "    def generate_random_images(self):\n",
    "        return  [\n",
    "            np.random.randint(0, 256, (self.batch_size, *self.image_shape), dtype=np.uint8) \n",
    "            for _ in range(self.num_batches)\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's test it by showing an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RGBImageBatchGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Create the generator\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m generator = \u001b[43mRGBImageBatchGenerator\u001b[49m()\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Generate the image batches\u001b[39;00m\n\u001b[32m      7\u001b[39m batches = generator.generate_random_images()\n",
      "\u001b[31mNameError\u001b[39m: name 'RGBImageBatchGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the generator\n",
    "generator = RGBImageBatchGenerator()\n",
    "\n",
    "# Generate the image batches\n",
    "batches = generator.generate_random_images()\n",
    "\n",
    "# Display the first image of the first batch\n",
    "plt.imshow(batches[0][0])\n",
    "plt.title(\"First Random RGB Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Question 2: \n",
    " Create 2 randomly placed squares of size 50x50 pixels on each image. The squares\n",
    " Should not overlap. Turn all pixels in the first square in white and all pixels in the second\n",
    " square in black.\n",
    "\n",
    "Answer 2: \n",
    "Adds two randomly placed non-overlapping squares to each image:\n",
    "    - First square placed randomly\n",
    "    - Second square placed randomly with custom logic to avoid overlap\n",
    "\n",
    "Parameters:\n",
    "    - batch (np.ndarray): A batch of images of shape (N, H, W, 3)\n",
    "    - square_size (int): The size of the square sides\n",
    "\n",
    "Returns:\n",
    "    - Modified batch with squares added\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fixed version of the SquareGenerator class\n",
    "class SquareGenerator:\n",
    "    def __init__(self, square_size=50):\n",
    "        self.square_size = square_size\n",
    "\n",
    "    def generate_squares(self, batch):\n",
    "        \"\"\"\n",
    "        Add white and black squares to each image in the batch\n",
    "        \"\"\"\n",
    "        batch_copy = batch.copy()  # Work on a copy to avoid modifying original\n",
    "        h, w = batch_copy.shape[1], batch_copy.shape[2]\n",
    "\n",
    "        for img in batch_copy:\n",
    "            # First square (white)\n",
    "            x1 = np.random.randint(0, w - self.square_size)\n",
    "            y1 = np.random.randint(0, h - self.square_size)\n",
    "\n",
    "            # Second square (black) - non-overlapping\n",
    "            x2, y2 = self._generate_non_overlapping(x1, y1, h, w)\n",
    "            \n",
    "            # Draw squares on the image\n",
    "            img[y1:y1+self.square_size, x1:x1+self.square_size] = [255, 255, 255]  # white\n",
    "            img[y2:y2+self.square_size, x2:x2+self.square_size] = [0, 0, 0]        # black\n",
    "            \n",
    "        return batch_copy\n",
    "\n",
    "    def _generate_non_overlapping(self, x1, y1, height, width):\n",
    "        \"\"\"\n",
    "        Generate coordinates for a second square that doesn't overlap with the first\n",
    "        \"\"\"\n",
    "        attempts = 0\n",
    "        max_attempts = 100\n",
    "        \n",
    "        while attempts < max_attempts:\n",
    "            x2 = np.random.randint(0, width - self.square_size)\n",
    "            y2 = np.random.randint(0, height - self.square_size)\n",
    "            \n",
    "            # Check if squares overlap\n",
    "            if not self._squares_overlap(x1, y1, x2, y2):\n",
    "                return x2, y2\n",
    "            \n",
    "            attempts += 1\n",
    "        \n",
    "        # If we can't find a non-overlapping position, place it as far as possible\n",
    "        if x1 + self.square_size < width - self.square_size:\n",
    "            x2 = x1 + self.square_size\n",
    "        else:\n",
    "            x2 = max(0, x1 - self.square_size)\n",
    "        \n",
    "        if y1 + self.square_size < height - self.square_size:\n",
    "            y2 = y1 + self.square_size\n",
    "        else:\n",
    "            y2 = max(0, y1 - self.square_size)\n",
    "            \n",
    "        return x2, y2\n",
    "    \n",
    "    def _squares_overlap(self, x1, y1, x2, y2):\n",
    "        \"\"\"\n",
    "        Check if two squares overlap\n",
    "        \"\"\"\n",
    "        return not (x1 + self.square_size <= x2 or \n",
    "                   x2 + self.square_size <= x1 or \n",
    "                   y1 + self.square_size <= y2 or \n",
    "                   y2 + self.square_size <= y1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main public method generate_squares handles the overall task of adding squares to images.\n",
    "\n",
    "Helper methods _generate_non_overlapping and _squares_overlap encapsulate specific logic for coordinate generation and overlap checking.\n",
    "\n",
    "This makes the code modular and easy to maintain.\n",
    "\n",
    "batch_copy = batch.copy() prevents side effects on the input data, respecting immutability principles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more elegent way of doing this class could be adding:\n",
    "Helper _random_coords method reduces duplication when generating random coordinates.\n",
    "\n",
    "Using a for-loop with early return instead of while and manual counter.\n",
    "\n",
    "Simplified fallback: using modulo ensures placement wraps within bounds.\n",
    "\n",
    "Set the white square pixels to 255 instead of [255, 255, 255] â€” NumPy broadcasts single value across all channels automatically, so cleaner and faster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized version of the SquareGenerator class\n",
    "import numpy as np\n",
    "\n",
    "class SquareGenerator:\n",
    "    def __init__(self, square_size=50):\n",
    "        self.square_size = square_size\n",
    "\n",
    "    def generate_squares(self, batch):\n",
    "        batch_copy = batch.copy()\n",
    "        h, w = batch_copy.shape[1], batch_copy.shape[2]\n",
    "\n",
    "        for img in batch_copy:\n",
    "            x1, y1 = self._random_coords(w, h)\n",
    "            x2, y2 = self._random_coords_non_overlapping(w, h, x1, y1)\n",
    "\n",
    "            img[y1:y1+self.square_size, x1:x1+self.square_size] = 255  # white\n",
    "            img[y2:y2+self.square_size, x2:x2+self.square_size] = 0    # black\n",
    "            \n",
    "        return batch_copy\n",
    "\n",
    "    def _random_coords(self, width, height):\n",
    "        return (\n",
    "            np.random.randint(0, width - self.square_size),\n",
    "            np.random.randint(0, height - self.square_size),\n",
    "        )\n",
    "    \n",
    "    def _random_coords_non_overlapping(self, width, height, x1, y1):\n",
    "        max_attempts = 100\n",
    "        for _ in range(max_attempts):\n",
    "            x2, y2 = self._random_coords(width, height)\n",
    "            if not self._overlap(x1, y1, x2, y2):\n",
    "                return x2, y2\n",
    "\n",
    "        # Fallback: place second square at the closest non-overlapping position\n",
    "        x2 = (x1 + self.square_size) % (width - self.square_size)\n",
    "        y2 = (y1 + self.square_size) % (height - self.square_size)\n",
    "        return x2, y2\n",
    "\n",
    "    def _overlap(self, x1, y1, x2, y2):\n",
    "        return not (\n",
    "            x1 + self.square_size <= x2 or\n",
    "            x2 + self.square_size <= x1 or\n",
    "            y1 + self.square_size <= y2 or\n",
    "            y2 + self.square_size <= y1\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the class SquareGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your SquareGenerator class here (paste your code)\n",
    "\n",
    "# Instantiate generator\n",
    "generator = SquareGenerator(square_size=50)\n",
    "\n",
    "# Create a dummy batch of 5 images, each 256x512 with 3 channels\n",
    "batch_size = 5\n",
    "image_shape = (256, 512, 3)\n",
    "dummy_batch = np.random.randint(0, 256, (batch_size, *image_shape), dtype=np.uint8)\n",
    "\n",
    "# Generate squares on the batch\n",
    "output_batch = generator.generate_squares(dummy_batch)\n",
    "\n",
    "# Check results and visualize one image\n",
    "print(\"Original batch shape:\", dummy_batch.shape)\n",
    "print(\"Output batch shape:\", output_batch.shape)\n",
    "\n",
    "# Display the first image before and after\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axes[0].imshow(dummy_batch[0])\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(output_batch[0])\n",
    "axes[1].set_title(\"Image with Squares\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Crop each image randomly so that it is a square of size 200x200 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop_200x200(batch):\n",
    "    cropped_batch = []\n",
    "\n",
    "    for img in batch:\n",
    "        h,w = img.shape[:2]\n",
    "        if h < 200 or w < 200:\n",
    "            raise ValueError(\"Image smaller than 200x200; cannot crop.\")\n",
    "        x = np.random.randint(0, w - 200 + 1)\n",
    "        y = np.random.randint(0, h - 200 + 1)\n",
    "\n",
    "        cropped = img[y:y+200, x:x+200]\n",
    "        cropped_batch.append(cropped)\n",
    "\n",
    "    return np.array(cropped_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. For each batch (batch_1-5), and each color (White / Black) calculate the average, standard\n",
    "deviation, minimum and maximum number of pixels in this color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# First, let's create a complete pipeline that processes all batches\n",
    "def process_all_batches_and_calculate_stats():\n",
    "    # Step 1: Generate the batches\n",
    "    generator = RGBImageBatchGenerator()\n",
    "    batches = generator.generate_random_images()\n",
    "    # Step 2: Process each batch through the pipeline\n",
    "    processed_data = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(batches):\n",
    "        batch_name = f\"batch_{batch_idx + 1}\"\n",
    "        print(f\"Processing {batch_name}...\")\n",
    "\n",
    "        # Add squares to the batch\n",
    "        square_gen = SquareGenerator(square_size=50)\n",
    "        batch_with_squares = square_gen.generate_squares(batch.copy())\n",
    "     \n",
    "        # Crop each image in the batch\n",
    "        cropped_batch = random_crop_200x200(batch_with_squares)\n",
    "\n",
    "      \n",
    "        # Count pixels for each image in the batch\n",
    "        for img_idx, img in enumerate(cropped_batch):\n",
    "            # Count white pixels (RGB = [255, 255, 255])\n",
    "            white_pixels = np.sum(np.all(img == [255, 255, 255], axis=2))\n",
    "            \n",
    "            # Count black pixels (RGB = [0, 0, 0])\n",
    "            black_pixels = np.sum(np.all(img == [0, 0, 0], axis=2))\n",
    "            \n",
    "            # Add to processed data\n",
    "            processed_data.append({\n",
    "                'batch': batch_name,\n",
    "                'image_id': img_idx + 1,\n",
    "                'color': 'White',\n",
    "                'pixel_count': white_pixels\n",
    "            })\n",
    "            \n",
    "            processed_data.append({\n",
    "                'batch': batch_name,\n",
    "                'image_id': img_idx + 1,\n",
    "                'color': 'Black',\n",
    "                'pixel_count': black_pixels\n",
    "            })\n",
    "\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(processed_data)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have created our dataframe we can process aggreagations.\n",
    "This code above can be optimized by setting function variables for the processed_data for exemple. I will try to do it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Calculate statistics for pixel counts by batch and color\n",
    "\n",
    "Parameters:\n",
    "df: DataFrame with columns 'batch', 'color', 'pixel_count'\n",
    "\n",
    "Returns:\n",
    "DataFrame with statistics grouped by batch and color\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pixel_statistics(df):\n",
    "\n",
    "# Group by batch and color, then calculate statistics\n",
    "    stats = df.groupby(['batch', 'color'])['pixel_count'].agg([\n",
    "        ('Average', 'mean'),\n",
    "        ('Std_Deviation', 'std'),\n",
    "        ('Minimum', 'min'),\n",
    "        ('Maximum', 'max')\n",
    "    ]).round(2)\n",
    "\n",
    "    # Reset index to make batch and color regular columns\n",
    "    stats = stats.reset_index()\n",
    "    return stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will be displaying the different statistics calculated above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_detailed_results(stats_df):\n",
    "    \"\"\"\n",
    "    Display results in a formatted way for each batch and color\n",
    "    \"\"\"\n",
    "    print(\"PIXEL STATISTICS BY BATCH AND COLOR\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for batch in ['batch_1', 'batch_2', 'batch_3', 'batch_4', 'batch_5']:\n",
    "        print(f\"\\n{batch.upper()}:\")\n",
    "        batch_data = stats_df[stats_df['batch'] == batch]\n",
    "        \n",
    "        for color in ['White', 'Black']:\n",
    "            color_data = batch_data[batch_data['color'] == color]\n",
    "            if not color_data.empty:\n",
    "                row = color_data.iloc[0]\n",
    "                print(f\"  {color}:\")\n",
    "                print(f\"    Average: {row['Average']}\")\n",
    "                print(f\"    Std Dev: {row['Std_Deviation']}\")\n",
    "                print(f\"    Minimum: {row['Minimum']}\")\n",
    "                print(f\"    Maximum: {row['Maximum']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could orchestrated this pipeline with an orchestrator for exemple airflow or Kestra to execute the complete pipeline from generation to statistics calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we already used a dataframe before the statistic calculation we will rename the columns and transform to parquet format (which is a very wise choice as Parquet is very performant for OLAP oriented column wharehouse and it's compression options can highly reduce the run time and cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_parquet_format(stats_df):\n",
    "    \"\"\"\n",
    "    Transform the statistics DataFrame to the required Parquet format:\n",
    "    batch_id, white_avg, white_min, white_max, white_std, black_avg, black_min, black_max, black_std\n",
    "    \"\"\"\n",
    "    \n",
    "    # Separate white and black statistics\n",
    "    white_stats = stats_df[stats_df['color'] == 'White'].copy()\n",
    "    black_stats = stats_df[stats_df['color'] == 'Black'].copy()\n",
    "    \n",
    "    # Rename columns for white statistics\n",
    "    white_stats = white_stats.rename(columns={\n",
    "        'batch': 'batch_id',\n",
    "        'Average': 'white_avg',\n",
    "        'Minimum': 'white_min',\n",
    "        'Maximum': 'white_max',\n",
    "        'Std_Deviation': 'white_std'\n",
    "    })[['batch_id', 'white_avg', 'white_min', 'white_max', 'white_std']]\n",
    "    \n",
    "    # Rename columns for black statistics\n",
    "    black_stats = black_stats.rename(columns={\n",
    "        'Average': 'black_avg',\n",
    "        'Minimum': 'black_min',\n",
    "        'Maximum': 'black_max',\n",
    "        'Std_Deviation': 'black_std'\n",
    "    })[['batch', 'black_avg', 'black_min', 'black_max', 'black_std']]\n",
    "\n",
    " \n",
    "    # Merge white and black statistics\n",
    "    final_df = white_stats.merge(\n",
    "        black_stats, \n",
    "        left_on='batch_id', \n",
    "        right_on='batch',\n",
    "        how='inner'\n",
    "    ).drop('batch', axis=1)\n",
    "    \n",
    "    # Reorder columns to match expected format\n",
    "    column_order = [\n",
    "        'batch_id', \n",
    "        'white_avg', 'white_min', 'white_max', 'white_std',\n",
    "        'black_avg', 'black_min', 'black_max', 'black_std'\n",
    "    ]\n",
    "    \n",
    "    final_df = final_df[column_order]\n",
    "    \n",
    "    return final_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the following function will save data to parquet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_parquet_with_validation(df, filename='batch_pixel_statistics.parquet'):\n",
    "    \"\"\"\n",
    "    Save DataFrame to Parquet file with validation\n",
    "    \"\"\"\n",
    "        # Validate DataFrame structure\n",
    "    expected_columns = [\n",
    "        'batch_id', \n",
    "        'white_avg', 'white_min', 'white_max', 'white_std',\n",
    "        'black_avg', 'black_min', 'black_max', 'black_std'\n",
    "    ]\n",
    "        \n",
    "    if list(df.columns) != expected_columns:\n",
    "        raise ValueError(f\"DataFrame columns don't match expected format.\\n\"\n",
    "                        f\"Expected: {expected_columns}\\n\"\n",
    "                        f\"Got: {list(df.columns)}\")\n",
    "        \n",
    "    # Save as Parquet\n",
    "    df.to_parquet(filename, index=False, engine='pyarrow')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Package your code as a Docker container:\n",
    "\n",
    "I created a dockerfile to build the docker image with a slim python image as the base, installing c and c++ used library for numpy and erase /var/lib/apt/lists/ which contains package list metadata downloaded during apt-get update to reduce the image size.\n",
    "\n",
    "In the case we are building a state of the art python code, we will execute the main.py here we could just execute the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. In the context of AWS, how would you deploy this code?\n",
    "\n",
    "Object Storage --> S3: Object oriented storage of AWS\n",
    "\n",
    "triggered only when 5 batches of 20 images are available -> Lambda1 -> DynamoDB for batch tracker and Lambda1 -> SQS for buffering the batch in a queue.\n",
    "\n",
    "SQS --> ECS to Processing the Container\n",
    "ECS --> RDS for our statistics needs\n",
    "\n",
    "Triggering notifications can be done in different ways.\n",
    "Either we use SNS\n",
    "ECS --> SNS we need to create a topic in SNS to trigger the notifications\n",
    "\n",
    "Or we could also get notified by the orchestrator itself by using on_success_callback which could avoid some \n",
    "To orchestrate this pipeline we would use MWAA for apache airflow\n",
    "\n",
    "To monitor the ECS and lambda function we could use cloudWatch if it's not enought we could setup a grafana and prometheus setup.\n",
    "\n",
    "graph TB\n",
    "    S3[S3 Bucket<br/>Raw Images] --> Lambda1[Lambda Trigger<br/>Image Counter]\n",
    "    Lambda1 --> DDB[DynamoDB<br/>Batch Tracker]\n",
    "    Lambda1 --> SQS[SQS Queue<br/>Processing Trigger]\n",
    "    \n",
    "    SQS --> ECS[ECS Fargate<br/>Processing Container]\n",
    "    ECS --> S3Results[S3 Bucket<br/>Results Storage]\n",
    "    ECS --> RDS[RDS PostgreSQL<br/>Statistics DB]\n",
    "    ECS --> SNS[SNS Topic<br/>Notifications]\n",
    "    \n",
    "    SNS --> Email[Email Notification]\n",
    "    SNS --> Webhook[Webhook/API]\n",
    "    \n",
    "    CloudWatch[CloudWatch<br/>Monitoring] --> ECS\n",
    "    CloudWatch --> Lambda1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
